---
title: "Skript 4 Analyse Workflow Throughput Time"
output:
  html_document: default
  pdf_document: default
date: "2023-02-09"
---
# Pakete laden
Laden Sie in diesem Code-Chunk alle Pakete, die sie benötigen. **Laden Sie Pakete immer am Anfang der Datei.**
```{r,echo=F }
library(car)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(nlme)
library(psych)
library(mvnormtest)
library(conflicted)
library(ez)
library(lm.beta)
library(knitr)
library(performance)
```

# Daten einlesen

```{r, echo = F}
getwd()
setwd("C:/Users/Katharina Wenderott/Documents/22.02/IfPS/quantib/Daten")
final <- read.csv("C:/Users/Katharina Wenderott/Documents/22.02/IfPS/quantib/Daten/20230505_final.csv")

```

Laptop
setwd("C:/Users/Katharina Wenderott/Documents/22.02/IfPS/quantib/Daten")
final <- read.csv("C:/Users/Katharina Wenderott/Documents/22.02/IfPS/quantib/Daten/final.csv")

UKB
setwd("C:/Users/50117334/sciebo/ifps/quantib/Daten")
final <- read.csv("C:/Users/50117334/sciebo/IfPS/quantib/Daten/final.csv")


# 1. Modell bauen

## Need for Multilevel
Baseline Model: in which only the intercept is included.
```{r}
interceptOnly <-gls(log_time ~ 1, data = final, method = "ML")
```

Include variation in intercepts: now the intercepts are allowed to vary across contexts, to see whether the fit of the model has improved.
```{r}
randomInterceptOnly <-lme(log_time ~ 1, data = final, random = ~1|pseudo, method = "ML")
```
Modellvergleich via ANOVA: Assessing the need for a multilevel model. If varying intercepts improve the modelfit, continue with multilevel modelling.
```{r}
anova(interceptOnly, randomInterceptOnly)
```

--> Modellverbesserung daher Random Intercepts

### mit Phase als Prädiktor

```{r}
mt_1 <- nlme::gls(log_time ~ phase, data = final, method = "ML")

mt_2 <- nlme::lme(log_time ~ phase,
                          data = final, random = ~1 | pseudo,
                          method = "ML")

anova(mt_1, mt_2)
```
--> Modellverbesserung durch random Intercepts

### Random Slopes
```{r}
mt_3 <- nlme::lme(log_time ~ phase,
                          data = final, random = ~phase | pseudo,
                          method = "ML", control = lmeControl(opt = 'optim'))
anova(mt_2, mt_3)
```
--> Keine Modellverbesserung durch random slopes

## PI-RADS aufnehmen

```{r}
mt_4 <- nlme::lme(log_time ~ phase*PI.RADS,
                          data = final, random = ~1 | pseudo,
                          method = "ML")

anova(mt_2, mt_4)
```
--> Modellverbesserung durch PI.RADS

# 2. Zusammenfassung finales Modell

Log(Zeit)~Phase*PI-RADS

```{r}
summary(mt_4)
nlme::intervals(mt_4)
```

# 3. Varianzaufklärung

```{r}
# Nakagawa & Schielzeth's (2013)

r2_nakagawa(mt_4)

```


# 4. Annahmen testen

https://ademos.people.uic.edu/Chapter18.html

## Assumption 1 - Linearity

A regression analysis is meant to fit the best rectilinear line that explains the most data given your set of parameters. Therefore, the base models rely on the assumption that your data follows a straight line (though the models can be expanded to handle curvilinear data).

Graphically, plotting the model residuals (the difference between the observed value and the model-estimated value) vs the predictor is one simple way to test. If a pattern emerges (anything that looks non-random), a higher order term may need to be included or you may need to mathematically trans

```{r}
plot(mt_4)
Plot.Model.F.Linearity1<-plot(resid(mt_4),mt_4$time_cor) # sollte zufällig aussehen
```

## Assumption 2 Homogeneity of Variance

Regression models assume that variance of the residuals is equal across groups. In this case, the groups we’re referring to are at the individual (i.e. subject) level.

R is an excellent program for extracting and storing your model residuals. After we have them in place, we can do a simple ANOVA to determine if they’re different for each person. This procedure is a variation of “Levene’s Test”. Essentially, we’ll extract the residuals from the model, place them in our original table, take their absolute value, and then square them (for a more robust analysis with respect to issues of normality, see Glaser 2006). Finally we’ll take a look at the ANOVA of the between subjects residuals. Let’s give it a shot below:

```{r}
#for this portion of the analysis, we need to revisit about statistical significance - since the assumption is that the variance is not going to differ, we would hope to see NO STATISTICAL DIFFERENCES in the following procedure (i.e. p>0.05) to confirm that -

final$Model.F.Res1<- residuals(mt_4) #extracts the residuals and places them in a new column in our original data table
final$Abs.Model.F.Res1 <-abs(final$Model.F.Res1) #creates a new column with the absolute value of the residuals
final$Model.F.Res21 <- final$Abs.Model.F.Res1^2 #squares the absolute values of the residuals to provide the more robust estimate
Levene.Model.F1 <- lm(Model.F.Res21 ~ pseudo, data=final) #ANOVA of the squared residuals
anova(Levene.Model.F1) #displays the results
plot(final$Model.F.Res21,x=as.factor(final$pseudo))
```
Levene Test signifikant 

## Assumption 3: The residuals of the model are normally distributed.

Regression models don’t require that outcome variables need to be normally distributed (see: Logistic or Poisson regression models), however MLM assume that the residuals of the analysis ARE normally distributed.

QQ plots (which are easily obtained in standard regression modeling in R) can provide an estimation of where the standardized residuals lie with respect to normal quantiles. Strong deviation from the provided line indicates that the residuals themselves are not normally distributed.



```{r}
#We ll need few packages
library(effects)
library(sjPlot)
#Try with model_plot (argument for type can be varied)
plot_model(mt_4, type='diag') # you can ajust type (see package info: ?plot_model)
```




# 5. Analyse einzelner Zeitpunkte

## Zeitpunkt t1

### Datensatz NA
```{r}

df <- final[,c( "observation", "phase", "PI.RADS", "log_t1", "pseudo", "i_rate")]
df <- drop_na(df)

```

### Modell t1
```{r}
mt1_4 <- nlme::lme(log_t1 ~ phase*PI.RADS,
                          data = df, random = ~1 | pseudo,
                          method = "ML")
```

### Zusammenfassung t1
```{r}
summary(mt1_4)
nlme::intervals(mt1_4)
```

## Zeitpunkte 2 & 3

### Modell t23

```{r}
mt_23 <- nlme::lme(log_t23 ~ phase*PI.RADS,
                          data = final, random = ~1 | pseudo,
                          method = "ML")
```

### Zusammenfassung t23

```{r}
summary(mt_23)
nlme::intervals(mt_23)

```


### Subruppen Analyse Interaktion

#### Dichotomisieren von Pi.RADS
```{r}
final$pi_dicho <- ifelse(final$PI.RADS < 4, "Low (1,2,3)", "High (4,5)")
pi_low <- final$pi_dicho=="Low (1,2,3)"
pi_high <- final$pi_dicho=="High (4,5)"

```

#### Niedriger PI.RADS

```{r}
low <- nlme::lme(log_t23 ~ phase,
                          data = final, random = ~1 | pseudo, subset = pi_low,
                          method = "ML")


summary(low)
intervals(low)
```

#### Hoher PI:RADS

```{r}
high <- nlme::lme(log_t23 ~ phase,
                          data = final, random = ~1 | pseudo, subset = pi_high,
                          method = "ML")


summary(high)
intervals(high)
```

#### Deskriptive Werte nach PI-RADS

```{r}
final |> 
  group_by(phase, pi_dicho) |> 
  summarise( n = n(),
    M = mean(t23_cor)/60,
    SD = sd(t23_cor)/60) %>% 
  dplyr::mutate_if(is.numeric, format, 1)
```


#### Interaktion Grafik 
```{r}
library(sjmisc)

final$t23_min <- as.numeric(final$t23_cor)/60

plotIA <- ggplot(final, aes(x = phase, y = t23_min, linetype = pi_dicho))

plotIA + stat_summary(fun.y = mean, geom = "point") +  stat_summary(fun.y = mean, geom = "line",  aes(group = pi_dicho)) + stat_summary(fun.data = mean_se,  geom = "errorbar", width = .1) + 
  labs(x = "CAD implementation",
       y = "Mean workflow throughput time (in Minutes)", linetype = "PI-RADS dichotomized") +
  scale_x_discrete(limits = c("pre", "post")) + 
  guides(linetype = guide_legend(reverse = TRUE)) +
  theme_classic()
```

